---
title: "Text Processing"
author: Gary Nguyen
---

## 0. INITIAL SETUP

```{r installing_packages, echo = FALSE, message = FALSE, warning = FALSE, results = 'hide'}

# Installing packages
if(!require(devtools, quietly = TRUE)) install.packages('devtools')
if(!require(pander, quietly = TRUE)) install.packages('pander')
if(!require(knitr, quietly = TRUE)) install.packages('knitr')
if(!require(dplyr, quietly = TRUE)) install.packages('dplyr')
if(!require(tidyr, quietly = TRUE)) install.packages('tidyr')
if(!require(stringr, quietly = TRUE)) install.packages('stringr')
if(!require(lubridate, quietly = TRUE)) install.packages('lubridate')
if(!require(purrr, quietly = TRUE)) install.packages('purrr')
if(!require(DT, quietly = TRUE)) install.packages('DT')
if(!require(tidytext, quietly = TRUE)) install.packages('tidytext')
if(!require(ggplot2, quietly = TRUE)) install.packages('ggplot2')
if(!require(textstem, quietly = TRUE)) install.packages('textstem')
if(!require(tm, quietly = TRUE)) install.packages('tm')
if(!require(splitstackshape, quietly = TRUE)) install.packages('splitstackshape')
if(!require(text2vec, quietly = TRUE)) install.packages('text2vec')
if(!require(reshape, quietly = TRUE)) install.packages('reshape')
if(!require(readr, quietly = TRUE)) install.packages('readr')
if(!require(zoo, quietly = TRUE)) install.packages('zoo')
if(!require(keras, quietly = TRUE)) install.packages('keras')
if(!require(zeallot, quietly = TRUE)) install.packages('zeallot')
if(!require(glue, quietly = TRUE)) install.packages('glue')

pkg <- c(
  'devtools',
  'pander',
  'tidyverse',
  'lubridate',
  'DT',
  'tidytext',
  'textstem',
  'tm',
  'splitstackshape',
  'text2vec',
  'reshape',
  'zoo',
  'keras',
  'zeallot',
  'glue'
)

invisible(lapply(pkg, library, character.only = TRUE))
options(warn=0)

devtools::load_all()
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r data_dir}
data_dir <- file.path(here::here(), 'data')
```

## 1. PROCESSING GOLD-STANDARD DATASET

```{r loading_data_gold_standard, message = FALSE, warning = FALSE, results = 'hide'}
file_name <- file.path(data_dir, 'gold_standard_HF_150.csv')

gold_standard_raw_data <- file_name %>% 
  readr::read_csv()

c(gold_standard_sentence_level, gold_standard_note_level) %<-% prc_gold_standard(gold_standard_raw_data)
```

```{r data_gold_standard_basic_stats_1, message = FALSE, warning = FALSE, results = 'hide'}
######################################################
# BASIC STAT 1: NUMBER OF SENTENCE & NUMBER OF NOTE
# AND NUMBER OF SENTENCE PER NOTE
######################################################
# There are 17,246 sentences in the gold standard dataset
gold_standard_num_sentence <- gold_standard_sentence_level %>% nrow()
print(glue('The number of sentences in the gold-standard dataset is {gold_standard_num_sentence}.'))

# There are 143 notes 
gold_standard_num_note <- gold_standard_note_level %>% nrow()
print(glue('The number of notes in the gold-standard dataset is {gold_standard_num_sentence}.'))

gold_standard_sentence_level %>% 
  group_by(report_no) %>% 
  summarize(num_sentence = n()) %>% 
  ggplot(aes(x = report_no, y = num_sentence)) + 
  geom_bar(stat="identity")

num_sentence <- gold_standard_sentence_level %>% 
  group_by(report_no) %>% 
  summarize(num_sentence = n()) %>% 
  pull(num_sentence)
#  0%   25%   50%   75%  100% 
#  2   82.5   113 144.5  284 
quantile(num_sentence)  
```

```{r data_gold_standard_basic_stats_2, message = FALSE, warning = FALSE, results = 'hide'}
######################################################
# BASIC STAT 2: NUMBER OF WORDS PER SENTENCES
######################################################
# 0%  25%  50%  75% 100% 
# 1    6   10   16  392
num_word <- gold_standard_sentence_level %>% 
  mutate(sentence_length = sapply(strsplit(note_processed, " "), length)) %>% 
  pull(sentence_length)
quantile(num_word)

# Two groups: normal sentence and sentence head
# 0%  25%  50%  75% 100% 
# 8   34   53   67  105
num_word_head <- gold_standard_sentence_level %>% 
  mutate(sentence_length = sapply(strsplit(note_processed, " "), length)) %>%
  filter(report_head) %>% 
  pull(sentence_length)
quantile(num_word_head)

# 0%  25%  50%  75% 100% 
# 1    6   10   16  392 
num_word_normal <- gold_standard_sentence_level %>% 
  mutate(sentence_length = sapply(strsplit(note_processed, " "), length)) %>%
  filter(!report_head) %>% 
  pull(sentence_length)
quantile(num_word_normal)
```

```{r data_gold_standard_basic_stats_3, message = FALSE, warning = FALSE, results = 'hide'}
######################################################
# BASIC STAT 3: LABEL COUNT
######################################################
# Sentence Level
# Dyspnea, Chest pain, Fatique, Nausea, Cough
gold_standard_sentence_level %>% 
  mutate_if(is.numeric, list(sum)) %>% 
  slice(1) %>% 
  select(-note_processed, 
         -report_head,
         -report_no,
         -with_labels) %>% 
  gather(key = symptoms, value = num_labels) %>% 
  arrange(desc(num_labels)) %>% 
  slice(1:5)

# Note Level
# Dyspnea, Chest pain, Fatique, Nausea, Cough
gold_standard_note_level %>% 
  mutate_if(is.numeric, list(sum)) %>% 
  slice(1) %>% 
  select(-note_processed, 
         -report_no) %>% 
  gather(key = symptoms, value = num_labels) %>% 
  arrange(desc(num_labels)) %>% 
  slice(1:5)
```

## 2. PROCESSING TRAINING DATASET

```{r loading_data_training, message = FALSE, warning = FALSE, results = 'hide'}
file_name_training <- file.path(data_dir, 'labeled-data-2019-08-02_12-51.csv')

training_raw_data <- file_name_training %>% readr::read_csv()
c(training_sentence_level, training_note_level) %<-% prc_training_data(training_raw_data)
```

```{r data_training_basic_stats_1, message = FALSE, warning = FALSE, results = 'hide'}
######################################################
# BASIC STAT 1: NUMBER OF SENTENCE & NUMBER OF NOTE
# AND NUMBER OF SENTENCE PER NOTE
######################################################
# There are 729,059 sentences in the gold standard dataset
training_num_sentence <- training_sentence_level %>% nrow()
print(glue('The number of sentences in the training dataset is {training_num_sentence}.'))

# There are 7,773 notes 
training_num_note <- training_note_level %>% nrow()
print(glue('The number of notes in the training dataset is {training_num_note}.'))

training_sentence_level %>% 
  group_by(report_no) %>% 
  summarize(num_sentence = n()) %>% 
  ggplot(aes(x = report_no, y = num_sentence)) + 
  geom_bar(stat = 'identity')

# 0%  25%  50%  75% 100% 
#  1   60   85  118  553
training_num_sentence <- training_sentence_level %>% 
  group_by(report_no) %>% 
  summarize(num_sentence = n()) %>% 
  pull(num_sentence)
quantile(training_num_sentence)  
```

```{r}
symptoms <- training_sentence_level %>% colnames() %>% 
  .[!. %in% c('note_processed', 'report_head',
              'report_no', 'with_labels')]

for (s in symptoms) {
  
  p <- training_sentence_level %>% 
    dplyr::rename(selected_symptom = s) %>% 
    group_by(report_no, selected_symptom) %>% 
    summarize(num_sentence = n()) %>% 
    ungroup() %>% 
    mutate(selected_symptom = as.character(selected_symptom)) %>% 
    ggplot(aes(x = report_no, fill = selected_symptom)) +
    geom_density(alpha = 0.5, aes(fill = factor(selected_symptom))) + 
    scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) + 
    theme_hc() +
    ggtitle(glue('Density Plot of Number of Sentence, Stratified by {str_to_title(s)}.'))
  
  print(p)
}
```

```{r data_training_basic_stats_2, message = FALSE, warning = FALSE, results = 'hide'}
######################################################
# BASIC STAT 2: NUMBER OF WORDS PER SENTENCES
######################################################
# 0%  25%  50%  75% 100% 
#  1    6   10   16 1457
training_num_word <- training_sentence_level %>% 
  mutate(sentence_length = sapply(strsplit(note_processed, " "), length)) %>% 
  pull(sentence_length)
quantile(training_num_word)

# Two groups: normal sentence and sentence head
# 0%  25%  50%  75% 100% 
#  5   30   41   58  520
training_num_word_head <- training_sentence_level %>% 
  mutate(sentence_length = sapply(strsplit(note_processed, " "), length)) %>%
  filter(report_head) %>% 
  pull(sentence_length)
quantile(training_num_word_head)

# 0%  25%  50%  75% 100% 
#  1    6   10   15 1457 
training_num_word_normal <- training_sentence_level %>% 
  mutate(sentence_length = sapply(strsplit(note_processed, " "), length)) %>%
  filter(!report_head) %>% 
  pull(sentence_length)
quantile(training_num_word_normal)
```

```{r data_training_basic_stats_3, message = FALSE, warning = FALSE, results = 'hide'}
######################################################
# BASIC STAT 3: LABEL COUNT
######################################################
# Sentence Level
# Dyspnea, Chest pain, Fatique, Nausea, Cough
training_sentence_level %>% 
  mutate_if(is.numeric, list(sum)) %>% 
  slice(1) %>% 
  select(-note_processed, 
         -report_head,
         -report_no) %>% 
  gather(key = symptoms, value = num_labels) %>% 
  arrange(desc(num_labels)) %>% 
  slice(1:5)

# Note Level
# Dyspnea, Chest pain, Fatique, Nausea, Cough
training_note_level %>% 
  mutate_if(is.numeric, list(sum)) %>% 
  slice(1) %>% 
  select(-note_processed, 
         -report_no) %>% 
  gather(key = symptoms, value = num_labels) %>% 
  arrange(desc(num_labels)) %>% 
  slice(1:5)
```

## 3. MAKING TRAIN-VALIDATION-TEST SET

- Select: Dyspnea, Chest pain, Fatique, Nausea, Cough
- Have to do sampling separately for sentence level and note level.

```{r choose_columns}
selected_gold_standard_sentence_level <- gold_standard_sentence_level %>% 
  transmute(note_processed,
            report_head, 
            report_no, 
            with_labels,
            dyspnea,
            chest.pain, 
            fatique, 
            nausea, 
            cough) %>% 
  mutate(with_labels = if_else(rowSums(.[5:9]) > 0, 1, 1))

selected_gold_standard_note_level <- gold_standard_note_level %>% 
    transmute(note_processed,
              report_no, 
              dyspnea,
              chest.pain, 
              fatique, 
              nausea, 
              cough)

selected_training_sentence_level <- training_sentence_level %>% 
  transmute(note_processed,
            report_head, 
            report_no, 
            with_labels,
            dyspnea,
            chest.pain, 
            fatique, 
            nausea, 
            cough) %>% 
  mutate(with_labels = if_else(rowSums(.[5:9]) > 0, 1, 0))

selected_training_note_level <- training_note_level %>% 
    transmute(note_processed,
              report_no, 
              dyspnea,
              chest.pain, 
              fatique, 
              nausea, 
              cough)
```

```{r sampling_sentence_level}
######################################################
# SAMPLING FOR SENTENCE LEVEL MODELS #################
######################################################

# TEST SET
gold_standard_sentence_level_with_labels <- selected_gold_standard_sentence_level %>% 
  filter(with_labels == 1)

gold_standard_sentence_level_with_labels %>% 
  select(-with_labels) %>% 
  mutate_if(is.numeric, list(sum)) %>% 
  slice(1) %>% 
  select(-note_processed, 
         -report_head,
         -report_no) %>% 
  gather(key = symptoms, value = num_labels) %>% 
  arrange(desc(num_labels)) %>% 
  mutate(num_row = nrow(gold_standard_sentence_level_without_labels),
         prop_label = num_labels/num_row)

# TRAIN SET
training_sentence_level_with_labels <- selected_training_sentence_level %>% 
  filter(with_labels == 1)

training_sentence_level_with_labels %>% 
  select(-with_labels) %>% 
  mutate_if(is.numeric, list(sum)) %>% 
  slice(1) %>% 
  select(-note_processed, 
         -report_head,
         -report_no) %>% 
  gather(key = symptoms, value = num_labels) %>% 
  arrange(desc(num_labels)) %>% 
  mutate(num_row = nrow(training_sentence_level_with_labels),
         prop_label = num_labels/num_row)

final_test_sentence_level <- gold_standard_sentence_level_with_labels
final_training_sentence_level <- training_sentence_level_with_labels
```

```{r sampling_note_level}
######################################################
# SAMPLING FOR SENTENCE LEVEL MODELS #################
######################################################

# TEST SET
gold_standard_note_level_with_labels <- selected_gold_standard_note_level %>% 
  mutate(with_labels = if_else(rowSums(.[3:7]) > 0, 1, 0)) %>% 
  filter(with_labels == 1)

selected_gold_standard_note_level %>% 
  mutate_if(is.numeric, list(sum)) %>% 
  slice(1) %>% 
  select(-note_processed, 
         -report_no) %>% 
  gather(key = symptoms, value = num_labels) %>% 
  arrange(desc(num_labels)) %>% 
  mutate(num_row = nrow(selected_gold_standard_note_level),
         prop_label = num_labels/num_row)

# TRAIN SET
training_note_level_with_labels <- selected_training_note_level %>% 
  mutate(with_labels = if_else(rowSums(.[3:7]) > 0, 1, 0)) %>% 
  filter(with_labels == 1)

training_note_level_with_labels %>% 
  select(-with_labels) %>% 
  mutate_if(is.numeric, list(sum)) %>% 
  slice(1) %>% 
  select(-note_processed, 
         -report_no) %>% 
  gather(key = symptoms, value = num_labels) %>% 
  arrange(desc(num_labels)) %>% 
  mutate(num_row = nrow(training_note_level_with_labels),
         prop_label = num_labels/num_row)

final_test_note_level <- selected_gold_standard_note_level
final_training_note_level <- training_note_level_with_labels
```

## 4. BASIC STATS FOR CHOSEN DATASET

```{r final_sentence_length}
######################################################
# SENTENCE LEVEL #####################################
######################################################

# 10%  20%  30%  40%  50%  60%  70%  80%  90% 100% 
#   5    7    9   12   14   17   20   26   39  591

final_full_sentence_level <- final_training_sentence_level %>% 
  bind_rows(final_test_sentence_level)

num_word_sentence_level_final <- final_full_sentence_level %>% 
  mutate(sentence_length = sapply(strsplit(note_processed, " "), length)) %>% 
  pull(sentence_length)
quantile(num_word_sentence_level_final, c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1))

# Count unique words: 15961
final_full_sentence_level %>% 
  unnest_tokens(output = word, input = note_processed, token = 'words') %>% 
  pull(word) %>% 
  unique() %>% 
  length()
```

```{r final_note_length}
######################################################
# NOTE LEVEL #########################################
######################################################

#   10%    20%    30%    40%    50%    60%    70%    80%    90%   100% 
# 653.6  831.0  967.0 1109.0 1256.0 1429.0 1631.0 1892.0 2334.8 5839.0 

final_full_note_level <- final_training_note_level %>% 
  bind_rows(final_test_note_level)

num_word_note_level_final <- final_full_note_level %>% 
  mutate(sentence_length = sapply(strsplit(note_processed, " "), length)) %>% 
  pull(sentence_length)
quantile(num_word_note_level_final, c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1))
```

## 5. SAVING

```{r saving}
file_path_training_sentence_level <- file.path(params$data_folder, "training_sentence_level.rds")
saveRDS(final_training_sentence_level, file_path_training_sentence_level)

file_path_test_sentence_level <- file.path(params$data_folder, "test_sentence_level.rds")
saveRDS(final_test_sentence_level, file_path_test_sentence_level)

file_path_training_note_level <- file.path(params$data_folder, "training_note_level.rds")
saveRDS(final_training_note_level, file_path_training_note_level)

file_path_test_note_level <- file.path(params$data_folder, "test_note_level.rds")
saveRDS(final_test_note_level, file_path_test_note_level)
```

















