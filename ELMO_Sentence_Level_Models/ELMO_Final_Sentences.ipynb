{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs:\n",
    "\n",
    "* Training Set: 'labeled-data-2019-07-18_14-22.csv': sentence level training dataset.\n",
    "* Test Set: 'gold_standard_HF_150.csv': sentence level test set.\n",
    "* Label: dyspnea.\n",
    "\n",
    "Reason for sentence level:\n",
    "* ELMO requires a lot of computational resource and long training time. Training time increases exponentially with the length of the notes. \n",
    "* This serves as a starting point, I will find more computational resource to train on whole note level.\n",
    "\n",
    "### Outputs:\n",
    "\n",
    "* model_elmo_weights_dyspnea_sentences_unbalanced.h5\n",
    "* model_elmo_weights_dyspnea_sentences_balanced.h5\n",
    "* model_elmo_weights_dyspnea_sentences_unbalanced.png\n",
    "* model_elmo_weights_dyspnea_sentences_balanced.png\n",
    "* predicts_unbalanced.csv\n",
    "* predicts_balanced.csv\n",
    "* confusion_matrix_unbalanced.csv\n",
    "* confusion_matrix_balanced.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Loading packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from keras.layers import Input, Lambda, Dense\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from numpy import asarray\n",
    "from numpy import savetxt\n",
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Setting Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/huynguyen/Desktop/cumc_research/Task1_BERT_or_Elmo\")\n",
    "df_train_path = os.getcwd() + \"/labeled-data-2019-07-18_14-22.csv\"\n",
    "df_test_path = os.getcwd() + \"/gold_standard_HF_150.csv\"\n",
    "elmo_module_path = os.getcwd() + \"/module/module_elmo3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_model_path_balanced = os.getcwd() + \"/model_elmo_weights_dyspnea_sentences_balanced.h5\"\n",
    "model_plot_path_balanced = os.getcwd() + \"/model_elmo_weights_dyspnea_sentences_balanced.png\"\n",
    "elmo_predict_path_balanced = os.getcwd() + \"/predicts_balanced.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_model_path_unbalanced = os.getcwd() + \"/model_elmo_weights_dyspnea_sentences_unbalanced.h5\"\n",
    "model_plot_path_unbalanced = os.getcwd() + \"/model_elmo_weights_dyspnea_sentences_unbalanced.png\"\n",
    "elmo_predict_path_unbalanced = os.getcwd() + \"/predicts_unbalanced.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def replace_contraction(text):\n",
    "    contraction_patterns = [(r'won\\'t', 'will not'),\n",
    "                            (r'can\\'t', 'can not'),\n",
    "                            (r'i\\'m', 'i am'),\n",
    "                            (r'ain\\'t', 'is not'),\n",
    "                            (r'(\\w+)\\'ll', '\\g<1> will'),\n",
    "                            (r'(\\w+)n\\'t', '\\g<1> not'),\n",
    "                            (r'(\\w+)\\'ve', '\\g<1> have'),\n",
    "                            (r'(\\w+)\\'s', '\\g<1> is'),\n",
    "                            (r'(\\w+)\\'re', '\\g<1> are'),\n",
    "                            (r'(\\w+)\\'d', '\\g<1> would'),\n",
    "                            (r'&', 'and'),\n",
    "                            (r'dammit', 'damn it'),\n",
    "                            (r'dont', 'do not'),\n",
    "                            (r'wont', 'will not')]\n",
    "    patterns = [(re.compile(regex), repl) for (regex, repl) in contraction_patterns]\n",
    "    for (pattern, repl) in patterns:\n",
    "        (text, count) = re.subn(pattern, repl, text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def replace_links(text, filler=' '):\n",
    "        text = re.sub(r'((http|https)\\:\\/\\/)?[a-zA-Z0-9\\.\\/\\?\\:@\\-_=#]+\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\/\\?\\:@\\-_=#])*',\n",
    "                      filler, text).strip()\n",
    "        return text\n",
    "\n",
    "def remove_numbers(text):\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    return text\n",
    "\n",
    "def str_len(text):\n",
    "    return len(text.split())\n",
    "\n",
    "def cleanText(text):\n",
    "    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    text = replace_contraction(text)\n",
    "    text = replace_links(text, \"link\")\n",
    "    text = remove_numbers(text)\n",
    "    text = re.sub(r'[,!@#$%^&*)(|/><\";:.?\\'\\\\}{]',\"\",text)\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Loading Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_training_set(df_train_path, subset = 0.1, balanced = False):\n",
    "    \n",
    "    # Loading and processing the sentence-level dataset\n",
    "    df_train = pd.read_csv(df_train_path)\n",
    "    df_train_dyspnea = df_train[['Note', 'Dyspnea (# of simclins)']]\n",
    "    df_train_dyspnea['Dyspnea (# of simclins)'] = df_train_dyspnea['Dyspnea (# of simclins)'].fillna(0.0)\n",
    "    df_train_dyspnea['dyspnea'] = np.where(df_train_dyspnea['Dyspnea (# of simclins)'] > 0.0, 1, 0)\n",
    "    df_train_dyspnea = df_train_dyspnea[['Note', 'dyspnea']].reset_index()\n",
    "    df_train_dyspnea = df_train_dyspnea.drop('index', axis = 1)\n",
    "    \n",
    "    # Remove rows where 'Note' is empty\n",
    "    df_train_dyspnea = df_train_dyspnea[pd.notnull(df_train_dyspnea['Note'])]\n",
    "    df_train_dyspnea['sent_len'] = df_train_dyspnea['Note'].apply(str_len)\n",
    "    \n",
    "    # Clip the length of 'Note' to 35 words max.\n",
    "    df_train_dyspnea = df_train_dyspnea[df_train_dyspnea['sent_len'] < 35]\n",
    "    \n",
    "    # Subset\n",
    "    df_train_dyspnea = df_train_dyspnea.sample(frac = subset, random_state = 2019)\n",
    "    \n",
    "    if balanced:\n",
    "    # Balance the training set.\n",
    "        df_pos = df_train_dyspnea[df_train_dyspnea['dyspnea'] == 1]\n",
    "        df_neg = df_train_dyspnea[df_train_dyspnea['dyspnea'] == 0].sample(n = df_pos.shape[0], random_state = 2019)\n",
    "        df_train_dyspnea = pd.concat([df_pos, df_neg])\n",
    "        df_train_dyspnea = df_train_dyspnea.reset_index()\n",
    "        df_train_dyspnea.drop('index', inplace = True, axis = 1)\n",
    "    \n",
    "    # Final processing\n",
    "    df_train_dyspnea['Note'] = df_train_dyspnea['Note'].apply(cleanText)\n",
    "    df_train_dyspnea['Note'] = df_train_dyspnea['Note'].str.replace('\\s+', ' ', regex = True)    \n",
    "    \n",
    "    return df_train_dyspnea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Balanced Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = loading_training_set(df_train_path, subset = 0.1, balanced = True)\n",
    "X_train = np.array(df_train[\"Note\"])\n",
    "y_train = np.array(df_train[\"dyspnea\"])\n",
    "sum(y_train)/len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Unbalanced Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006426119064585087"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = loading_training_set(df_train_path, subset = 0.1)\n",
    "X_train = np.array(df_train[\"Note\"])\n",
    "y_train = np.array(df_train[\"dyspnea\"])\n",
    "sum(y_train)/len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Loading Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_test_set(df_test_path, balanced = False):\n",
    "    \n",
    "    # Loading and processing the sentence-level dataset\n",
    "    df = pd.read_csv(df_test_path)\n",
    "    for i in range(1, 5):\n",
    "        df['dyspnea_' + str(i)] = np.where(df['Category ' + str(i)] == 'Dyspnea', 1, 0)\n",
    "    df = df[['Note', 'dyspnea_1', 'dyspnea_2', 'dyspnea_3', 'dyspnea_4']]\n",
    "    df['dyspnea'] = df[['dyspnea_1', 'dyspnea_2', 'dyspnea_3', 'dyspnea_4']].sum(axis = 1)\n",
    "    df['dyspnea'] = np.where(df['dyspnea'] > 0, 1, 0)\n",
    "    df = df[['Note', 'dyspnea']]\n",
    "    \n",
    "    # Remove rows where 'Note' is empty\n",
    "    df = df[pd.notnull(df['Note'])]\n",
    "    df['sent_len'] = df['Note'].apply(str_len)\n",
    "    \n",
    "    # Clip the length of 'Note' to 35 words max.\n",
    "    df = df[df['sent_len'] < 35]\n",
    "    if balanced:\n",
    "        df_pos = df[df['dyspnea'] == 1]\n",
    "        df_neg = df[df['dyspnea'] == 0].sample(n = df_pos.shape[0], random_state = 2019)\n",
    "        df = pd.concat([df_pos, df_neg])\n",
    "        df = df.reset_index()\n",
    "        df.drop('index', inplace = True, axis = 1)\n",
    "    \n",
    "    # Final processing\n",
    "    df['Note'] = df['Note'].apply(cleanText)\n",
    "    df['Note'] = df['Note'].str.replace('\\s+', ' ', regex = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Balanced Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = loading_test_set(df_test_path, balanced = True)\n",
    "X_test = np.array(df_test[\"Note\"])\n",
    "y_test = np.array(df_test[\"dyspnea\"])\n",
    "sum(y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Unbalanced Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006663753550360498"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = loading_test_set(df_test_path)\n",
    "X_test = np.array(df_test[\"Note\"])\n",
    "y_test = np.array(df_test[\"dyspnea\"])\n",
    "sum(y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Modelling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_elmo(elmo_module_path, elmo_model_path, epochs=20, batch_size=256):\n",
    "    embed = hub.Module(elmo_module_path)\n",
    "    def ELMoEmbedding(x):\n",
    "        return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]\n",
    "    def build_model():\n",
    "        input_text = Input(shape=(1,), dtype=\"string\")\n",
    "        embedding = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text)\n",
    "        dense = Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(embedding)\n",
    "        pred = Dense(1, activation='sigmoid')(dense)\n",
    "        model = Model(inputs=[input_text], outputs=pred)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "        return model\n",
    "    model_elmo_dyspnea = build_model()\n",
    "    with tf.Session() as session:\n",
    "        K.set_session(session)\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        session.run(tf.tables_initializer())\n",
    "        history = model_elmo_dyspnea.fit(X_train, y_train,\n",
    "                                         epochs=epochs,\n",
    "                                         batch_size=batch_size,\n",
    "                                         validation_split = 0.2)\n",
    "        model_elmo_dyspnea.save_weights(elmo_model_path)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(history, model_plot_path):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.figure(figsize = (6, 6))\n",
    "    plt.plot(epochs, acc, 'g', label='Training Acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation Acc')\n",
    "    plt.title('Training and validation Acc')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Acc')\n",
    "    plt.legend()\n",
    "    plt.savefig(model_plot_path, bbox_inches = 'tight', dpi = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Prediction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prediction(df_test, elmo_model_path, elmo_predict_path, elmo_module_path):\n",
    "    df_test_text = df_test['Note'].to_list()\n",
    "    test_text_to_pred = np.array(df_test_text, dtype=object)[:, np.newaxis]\n",
    "    embed = hub.Module(elmo_module_path)\n",
    "    def ELMoEmbedding(x):\n",
    "        return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]\n",
    "    def build_model():\n",
    "        input_text = Input(shape=(1,), dtype=\"string\")\n",
    "        embedding = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text)\n",
    "        dense = Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(embedding)\n",
    "        pred = Dense(1, activation='sigmoid')(dense)\n",
    "        model = Model(inputs=[input_text], outputs=pred)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "        return model\n",
    "    model_elmo_dyspnea = build_model()\n",
    "    with tf.Session() as session:\n",
    "        K.set_session(session)\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        session.run(tf.tables_initializer())\n",
    "        model_elmo_dyspnea.load_weights(elmo_model_path)\n",
    "        predicts = model_elmo_dyspnea.predict(test_text_to_pred)\n",
    "        savetxt(elmo_predict_path, predicts, delimiter=',')\n",
    "    return predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(predicts, df_test):\n",
    "    predicts = np.array(predicts)\n",
    "    predicts = np.where(predicts > 0.5, 1, 0)\n",
    "    y_test = np.array(df_test['dyspnea'])\n",
    "    return confusion_matrix(y_test, predicts), f1_score(y_test, predicts, average = 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Running Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training set\n",
    "df_train = loading_training_set(df_train_path, subset = 0.1)\n",
    "X_train = np.array(df_train[\"Note\"])\n",
    "y_train = np.array(df_train[\"dyspnea\"])\n",
    "\n",
    "# Prepare test set\n",
    "df_test = loading_test_set(df_test_path)\n",
    "X_test = np.array(df_test[\"Note\"])\n",
    "y_test = np.array(df_test[\"dyspnea\"])\n",
    "\n",
    "# Training Elmo\n",
    "history = train_elmo(elmo_module_path, elmo_model_path_unbalanced, epochs=5)\n",
    "plot_training(history, model_plot_path_unbalanced)\n",
    "\n",
    "# Running predictions\n",
    "predicts = run_prediction(df_test, elmo_model_path_unbalanced, elmo_predict_path_unbalanced, elmo_module_path)\n",
    "get_confusion_matrix(predicts, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training set\n",
    "df_train = loading_training_set(df_train_path, subset = 0.1, balanced = True)\n",
    "X_train = np.array(df_train[\"Note\"])\n",
    "y_train = np.array(df_train[\"dyspnea\"])\n",
    "\n",
    "# Prepare test set\n",
    "df_test = loading_test_set(df_test_path, balanced = True)\n",
    "X_test = np.array(df_test[\"Note\"])\n",
    "y_test = np.array(df_test[\"dyspnea\"])\n",
    "\n",
    "# Training Elmo\n",
    "history = train_elmo(elmo_module_path, elmo_model_path_balanced, epochs=5)\n",
    "plot_training(history, model_plot_path_balanced)\n",
    "\n",
    "# Running predictions\n",
    "predicts = run_prediction(df_test, elmo_model_path_balanced, elmo_predict_path_balanced, elmo_module_path)\n",
    "get_confusion_matrix(predicts, df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
